{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess( screen):\n",
    "    preprocessed= cv2.resize(screen, (84,84))  # 84 * 84 로 변경\n",
    "    preprocessed = np.dot(preprocessed[..., :3], [0.299, 0.587, 0.114])  # Gray scale 로 변경\n",
    "    # preprocessed: np.array = preprocessed.transpose((2, 0, 1))  # (C, W, H) 로 변경\n",
    "    preprocessed = preprocessed.astype('float32') / 255.\n",
    "\n",
    "    return torch.tensor(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils.replay_memory import ReplayBuffer\n",
    "from utils.save_tensorboard import *\n",
    "from models.dqn_image import DQN as Qnet\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "with open(\"configs/dqn.json\", \"r\") as config_json:\n",
    "    config = json.load(config_json)\n",
    "\n",
    "learning_rate = config['learning_rate']\n",
    "gamma = config['gamma']\n",
    "buffer_limit = 10000\n",
    "batch_size = config['batch_size']\n",
    "n_episodes = config['n_episodes']\n",
    "min_mem_size = config['min_mem_size']\n",
    "\n",
    "def main():\n",
    "    env = gym.make('CartPole-v1')\n",
    "    Summary_Writer=mk_SummaryWriter(\"experiments\",'DQN')\n",
    "    q = Qnet().to(device)\n",
    "    q_target = Qnet().to(device)\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    memory = ReplayBuffer(buffer_limit, device)\n",
    "\n",
    "    print_interval = 20\n",
    "    score = 0.0\n",
    "    max_score = -9999\n",
    "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "\n",
    "    for n_epi in range(n_episodes):\n",
    "        epsilon = max(0.01, 0.08 - 0.01 * (n_epi / 200))  # Linear annealing from 8% to 1%\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        height,width=84,84\n",
    "        history_initial=torch.zeros(4,height,width)\n",
    "        while not done:\n",
    "            a = q.sample_action(history_initial.float().to(device).unsqueeze(0), epsilon)\n",
    "\n",
    "            s_prime, r, done, info = env.step(a)\n",
    "\n",
    "            s_image=env.render(mode='rgb_array')\n",
    "\n",
    "            s_image=preprocess( s_image)\n",
    "            history_new=torch.cat((s_image.unsqueeze(0),history_initial[1:4]),0)    \n",
    "            \n",
    "            \n",
    "\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            memory.put((history_initial, a, r / 100.0, history_new, done_mask))\n",
    "            history_initial=history_new\n",
    "            s = s_prime\n",
    "            score += r\n",
    "            if done:\n",
    "                break\n",
    "            if max_score < score:\n",
    "                max_score = score\n",
    "\n",
    "        if memory.size() > min_mem_size:\n",
    "            for i in range(10):\n",
    "                s, a, r, s_prime, done_mask = memory.sample_b(batch_size)\n",
    "\n",
    "                q_out = q(s)\n",
    "                q_a = q_out.gather(1, a)\n",
    "\n",
    "                max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "                target = r + gamma * max_q_prime * done_mask\n",
    "                loss = F.smooth_l1_loss(q_a, target)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "            print(f\"[Episode {n_epi:5d}] Score: {score / print_interval:6.2f} | Max score: {max_score / print_interval:6.2f} | Buffer size: {memory.size():5d} | Epsilon: {epsilon * 100:2.1f}%\")\n",
    "            add_scalar(\"Score\",score/print_interval,n_epi,Summary_Writer)\n",
    "            add_scalar(\"Max Score\",max_score/print_interval,n_epi,Summary_Writer)\n",
    "            add_scalar(\"Buffer Size\",memory.size() /print_interval,n_epi,Summary_Writer)\n",
    "            add_scalar(\"Epsilon\",epsilon ,n_epi,Summary_Writer)\n",
    "            score = 0.0\n",
    "\n",
    "\n",
    "    env.close()\n",
    "    Summary_Writer.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Already Exists\n",
      "[Episode    20] Score:  12.25 | Max score:  12.20 | Buffer size:   245 | Epsilon: 7.9%\n",
      "[Episode    40] Score:  15.45 | Max score:  15.40 | Buffer size:   554 | Epsilon: 7.8%\n",
      "[Episode    60] Score:  11.55 | Max score:  15.40 | Buffer size:   785 | Epsilon: 7.7%\n",
      "[Episode    80] Score:  10.35 | Max score:  15.40 | Buffer size:   992 | Epsilon: 7.6%\n",
      "[Episode   100] Score:  12.50 | Max score:  15.40 | Buffer size:  1242 | Epsilon: 7.5%\n",
      "[Episode   120] Score:  12.05 | Max score:  15.40 | Buffer size:  1483 | Epsilon: 7.4%\n",
      "[Episode   140] Score:  13.35 | Max score:  15.40 | Buffer size:  1750 | Epsilon: 7.3%\n",
      "[Episode   160] Score:  11.75 | Max score:  15.40 | Buffer size:  1985 | Epsilon: 7.2%\n",
      "[Episode   180] Score:  13.50 | Max score:  15.40 | Buffer size:  2255 | Epsilon: 7.1%\n",
      "[Episode   200] Score:  13.85 | Max score:  15.40 | Buffer size:  2532 | Epsilon: 7.0%\n",
      "[Episode   220] Score:  20.20 | Max score:  20.15 | Buffer size:  2936 | Epsilon: 6.9%\n",
      "[Episode   240] Score:  20.20 | Max score:  20.15 | Buffer size:  3340 | Epsilon: 6.8%\n",
      "[Episode   260] Score:  14.35 | Max score:  20.15 | Buffer size:  3627 | Epsilon: 6.7%\n",
      "[Episode   280] Score:  13.95 | Max score:  20.15 | Buffer size:  3906 | Epsilon: 6.6%\n",
      "[Episode   300] Score:  18.95 | Max score:  20.15 | Buffer size:  4285 | Epsilon: 6.5%\n",
      "[Episode   320] Score:  15.85 | Max score:  20.15 | Buffer size:  4602 | Epsilon: 6.4%\n",
      "[Episode   340] Score:  19.60 | Max score:  20.15 | Buffer size:  4994 | Epsilon: 6.3%\n",
      "[Episode   360] Score:  20.10 | Max score:  20.15 | Buffer size:  5396 | Epsilon: 6.2%\n",
      "[Episode   380] Score:  15.70 | Max score:  20.15 | Buffer size:  5710 | Epsilon: 6.1%\n",
      "[Episode   400] Score:  15.35 | Max score:  20.15 | Buffer size:  6017 | Epsilon: 6.0%\n",
      "[Episode   420] Score:  14.35 | Max score:  20.15 | Buffer size:  6304 | Epsilon: 5.9%\n",
      "[Episode   440] Score:  16.35 | Max score:  20.15 | Buffer size:  6631 | Epsilon: 5.8%\n",
      "[Episode   460] Score:  16.80 | Max score:  20.15 | Buffer size:  6967 | Epsilon: 5.7%\n",
      "[Episode   480] Score:  15.50 | Max score:  20.15 | Buffer size:  7277 | Epsilon: 5.6%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Qnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_initial=torch.zeros(4,84,84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.sample_action(history_initial.float().to(device).unsqueeze(0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q(history_initial.float().to(device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
